# services/context_service.py
# ì¹´ì¹´ì˜¤í†¡ txt ì—…ë¡œë“œ ë¶„ì„ ì„œë¹„ìŠ¤ ë¡œì§

import logging
logger = logging.getLogger("uvicorn")
logger.info("[FastAPI] 0")

# logging.basicConfig(level=logging.INFO)
# logging.info("[FastAPI] integrated_analysis2.py í˜¸ì¶œ ì§ì „: ë¶„ì„ í”„ë¡œì„¸ìŠ¤ ì‹œì‘ (logging)")


from sqlalchemy.orm import Session
from fastapi import UploadFile
from models import analysis as analysis_model
from schemas import context as context_schema

import json

def parse_kakao_txt(file_content: str) -> dict:
    """
    ì¹´ì¹´ì˜¤í†¡ txt íŒŒì¼ íŒŒì‹± (ìƒ˜í”Œ ë²„ì „)
    - ì‹¤ì œë¡œëŠ” ë©”ì‹œì§€/ì‚¬ìš©ì/ì‹œê°„/ë³¸ë¬¸ ì¶”ì¶œ
    """
    lines = file_content.splitlines()
    messages = []

    for line in lines:
        if line.strip():
            messages.append({"message": line.strip()})

    return {"messages": messages}

import subprocess
import os
import uuid
from datetime import datetime




from sqlalchemy.orm import Session
from fastapi import UploadFile
from models import analysis as analysis_model
from schemas import context as context_schema

import json
import os
import uuid
from datetime import datetime

# Gemini API í˜¸ì¶œ í•¨ìˆ˜ ì¶”ê°€
def call_gemini_api_from_text(kakao_text: str, prompt_info: dict) -> dict:
    import google.generativeai as genai
    genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

    # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    prompt = f"""
ì•„ë˜ëŠ” ì¹´ì¹´ì˜¤í†¡ ëŒ€í™” ë‚´ìš©ì…ë‹ˆë‹¤:
{kakao_text}

ì•„ë˜ëŠ” ì¶”ê°€ ì •ë³´ì…ë‹ˆë‹¤:
{json.dumps(prompt_info, ensure_ascii=False)}

ìœ„ì˜ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì´ë²„ë¶ˆë§ ì—¬ë¶€ë¥¼ JSONìœ¼ë¡œ ë¶„ì„í•´ì¤˜.
    """

    model = genai.GenerativeModel("gemini-pro")
    response = model.generate_content(prompt)

    try:
        return json.loads(response.text)
    except json.JSONDecodeError:
        return {
            "error": "Invalid JSON returned by Gemini API",
            "raw_text": response.text
        }

import subprocess
import json
import os
import uuid
from datetime import datetime
from fastapi import UploadFile
from sqlalchemy.orm import Session
from models import analysis as analysis_model
from schemas import context as context_schema

def upload_and_analyze_kakao_chat(
    db: Session,
    user_id: int,
    file: UploadFile,
    prompt_info: str
) -> context_schema.UploadResponse:
    # ğŸ“Œ ì—…ë¡œë“œ ê²½ë¡œ ì¤€ë¹„
    upload_dir = f"./uploads/{datetime.now().strftime('%Y-%m-%d')}"
    os.makedirs(upload_dir, exist_ok=True)

    txt_path = os.path.join(upload_dir, f"{uuid.uuid4()}.txt")
    json_path = os.path.join(upload_dir, f"{uuid.uuid4()}.json")
    out_path = os.path.join(upload_dir, f"{uuid.uuid4()}_output.json")

    # ğŸ“Œ íŒŒì¼ ì €ì¥
    with open(txt_path, "wb") as f:
        f.write(file.file.read())

    # ğŸ“Œ prompt_info JSON ì €ì¥
    try:
        prompt_info_dict = json.loads(prompt_info) if prompt_info else {}
    except json.JSONDecodeError:
        prompt_info_dict = {"raw_prompt_info": prompt_info}

    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(prompt_info_dict, f, ensure_ascii=False, indent=2)

    # âœ… ì—¬ê¸°ì— ë¡œê·¸ ìœ ì§€
    logger.info("[FastAPI] 1")

    # ğŸ“Œ integrated_analysis2.py subprocess í˜¸ì¶œ
    result = subprocess.run(
        [
            "python", "integrated_analysis2.py",
            txt_path,
            json_path,
            out_path
        ],
        text=True,
        encoding="utf-8"
    )

    if result.returncode != 0:
        print("STDOUT:", result.stdout)
        print("STDERR:", result.stderr)
        raise Exception(f"integrated_analysis2.py ì‹¤í–‰ ì‹¤íŒ¨:\n{result.stderr}")

    # ğŸ“Œ ê²°ê³¼ JSON ë¡œë“œ
    with open(out_path, "r", encoding="utf-8") as f:
        analysis_result = json.load(f)

    # ğŸ“Œ DB ì €ì¥
    db_analysis = analysis_model.Analysis(
        user_id=user_id,
        file_name=file.filename,
        analysis_result=analysis_result
    )
    db.add(db_analysis)
    db.commit()
    db.refresh(db_analysis)

    return context_schema.UploadResponse(
        success=True,
        message="integrated_analysis2.py ê¸°ë°˜ ì¹´ì¹´ì˜¤í†¡ ë¶„ì„ ì™„ë£Œ",
        analysis_id=db_analysis.id
    )

